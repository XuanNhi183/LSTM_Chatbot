{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff5e982e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Có đôi khi\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "data = pd.read_csv(\"hoi_dap_vui.csv\")\n",
    "khach_hang = data[\"user_a\"].to_list()\n",
    "nhan_vien = data[\"user_b\"].to_list()\n",
    "def chat_bot_blue(cau_hoi):\n",
    "  diem_tuong_dong = 0\n",
    "  cau_tra_Loi = \"\"\n",
    "  for i in range(len(khach_hang)):\n",
    "    BLEU_score = nltk.translate.bleu_score.sentence_bleu([cau_hoi], khach_hang[i], weights = (0.5, 0.5))\n",
    "    if BLEU_score > diem_tuong_dong:\n",
    "      diem_tuong_dong = BLEU_score\n",
    "      cau_tra_Loi = nhan_vien [i]\n",
    "  return cau_tra_Loi\n",
    "print(chat_bot_blue(\"Bạn có bắt chuyện trước không\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95115764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from tensorflow.keras import layers, activations, models, preprocessing, utils\n",
    "questions = data[\"user_a\"].tolist()\n",
    "answers = data[\"user_b\"].tolist()\n",
    "answers_with_tags = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb7ee13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xóa đi cột bị rỗng\n",
    "for i in range( len( answers ) ):\n",
    "    if type( answers[i] ) == str:\n",
    "        answers_with_tags.append( answers[i] )\n",
    "    else:\n",
    "        questions.pop( i )\n",
    "answers = list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4300660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<START> Dễ thương, tóc dài, da trắng <END>\n"
     ]
    }
   ],
   "source": [
    "#gan nhan \n",
    "for i in range( len( answers_with_tags ) ) :\n",
    "    answers.append( '<START> ' + answers_with_tags[i] + ' <END>' )\n",
    "print(answers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c66777f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Số lượng từ trong từ điển: 3097\n"
     ]
    }
   ],
   "source": [
    "tokenizer = preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts( questions + answers )\n",
    "VOCAB_SIZE = len( tokenizer.word_index )+1\n",
    "print( 'Số lượng từ trong từ điển: {}'.format( VOCAB_SIZE ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa81472d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'end': 1,\n",
       " 'start': 2,\n",
       " 'không': 3,\n",
       " 'có': 4,\n",
       " 'gì': 5,\n",
       " 'đi': 6,\n",
       " 'mày': 7,\n",
       " 'bạn': 8,\n",
       " 'ở': 9,\n",
       " 'đâu': 10,\n",
       " 'nào': 11,\n",
       " 'làm': 12,\n",
       " 'thích': 13,\n",
       " 'học': 14,\n",
       " 'bao': 15,\n",
       " 'người': 16,\n",
       " 'chơi': 17,\n",
       " 'là': 18,\n",
       " 'ăn': 19,\n",
       " 'nhiêu': 20,\n",
       " 'chưa': 21,\n",
       " 'hay': 22,\n",
       " 'tao': 23,\n",
       " 'yêu': 24,\n",
       " 'quê': 25,\n",
       " 'rồi': 26,\n",
       " 'nhà': 27,\n",
       " 'được': 28,\n",
       " 'với': 29,\n",
       " 'sao': 30,\n",
       " 'trường': 31,\n",
       " 'phim': 32,\n",
       " 'đang': 33,\n",
       " 'tên': 34,\n",
       " 'mua': 35,\n",
       " 'ai': 36,\n",
       " 'mấy': 37,\n",
       " 'thế': 38,\n",
       " 'tết': 39,\n",
       " 'về': 40,\n",
       " 'mình': 41,\n",
       " 'xem': 42,\n",
       " 'năm': 43,\n",
       " 'vậy': 44,\n",
       " 'cũng': 45,\n",
       " 'tuổi': 46,\n",
       " 'muốn': 47,\n",
       " 'thì': 48,\n",
       " '1': 49,\n",
       " 'này': 50,\n",
       " 'của': 51,\n",
       " 'nhiều': 52,\n",
       " 'công': 53,\n",
       " 'như': 54,\n",
       " 'em': 55,\n",
       " 'đó': 56,\n",
       " 'ngày': 57,\n",
       " 'biết': 58,\n",
       " 'thể': 59,\n",
       " 'và': 60,\n",
       " 'còn': 61,\n",
       " 'khi': 62,\n",
       " 'ok': 63,\n",
       " '2': 64,\n",
       " 'đẹp': 65,\n",
       " 'thường': 66,\n",
       " 'vui': 67,\n",
       " 'chứ': 68,\n",
       " 'nhất': 69,\n",
       " 'sinh': 70,\n",
       " 'anh': 71,\n",
       " 'à': 72,\n",
       " 'cho': 73,\n",
       " 'con': 74,\n",
       " 'việc': 75,\n",
       " 'nước': 76,\n",
       " 'lắm': 77,\n",
       " 'game': 78,\n",
       " 'lâu': 79,\n",
       " 'một': 80,\n",
       " 'cao': 81,\n",
       " 'tính': 82,\n",
       " '3': 83,\n",
       " 'viên': 84,\n",
       " 'tiền': 85,\n",
       " 'máy': 86,\n",
       " 'nam': 87,\n",
       " 'lịch': 88,\n",
       " 'ra': 89,\n",
       " 'mà': 90,\n",
       " 'quận': 91,\n",
       " 'chung': 92,\n",
       " 'giờ': 93,\n",
       " 'áo': 94,\n",
       " 'crush': 95,\n",
       " 'gái': 96,\n",
       " 'gần': 97,\n",
       " '20': 98,\n",
       " 'du': 99,\n",
       " 'rảnh': 100,\n",
       " 'tháng': 101,\n",
       " 'gia': 102,\n",
       " 'điện': 103,\n",
       " 'chị': 104,\n",
       " 'trong': 105,\n",
       " 'bè': 106,\n",
       " 'triệu': 107,\n",
       " 'môn': 108,\n",
       " 'ngành': 109,\n",
       " '4': 110,\n",
       " 'mới': 111,\n",
       " 'tốt': 112,\n",
       " 'bình': 113,\n",
       " 'nay': 114,\n",
       " 'nghề': 115,\n",
       " 'thân': 116,\n",
       " 'vào': 117,\n",
       " 'nó': 118,\n",
       " 'thôi': 119,\n",
       " 'tại': 120,\n",
       " 'cậu': 121,\n",
       " 'nha': 122,\n",
       " 'hỏi': 123,\n",
       " 'tôi': 124,\n",
       " 'ổn': 125,\n",
       " 'đình': 126,\n",
       " 'giá': 127,\n",
       " 'ông': 128,\n",
       " 'để': 129,\n",
       " 'tình': 130,\n",
       " 'đà': 131,\n",
       " 'sản': 132,\n",
       " '5': 133,\n",
       " 'luôn': 134,\n",
       " 'xa': 135,\n",
       " 'đồ': 136,\n",
       " 'hàng': 137,\n",
       " 'thoại': 138,\n",
       " 'bồ': 139,\n",
       " 'ngoài': 140,\n",
       " 'đồng': 141,\n",
       " 'nghiệp': 142,\n",
       " 'ngon': 143,\n",
       " 'cái': 144,\n",
       " 'mẹ': 145,\n",
       " 'nghỉ': 146,\n",
       " 'chỗ': 147,\n",
       " 'nữa': 148,\n",
       " 'quan': 149,\n",
       " 'cả': 150,\n",
       " 'thành': 151,\n",
       " 'động': 152,\n",
       " 'thấy': 153,\n",
       " 'đại': 154,\n",
       " 'tin': 155,\n",
       " 'thông': 156,\n",
       " 'phòng': 157,\n",
       " 'sống': 158,\n",
       " 'từ': 159,\n",
       " 'dễ': 160,\n",
       " 'đặc': 161,\n",
       " 'chỉ': 162,\n",
       " 'lương': 163,\n",
       " 'minh': 164,\n",
       " 'lạt': 165,\n",
       " 'đây': 166,\n",
       " 'lúc': 167,\n",
       " 'loại': 168,\n",
       " 'đá': 169,\n",
       " 'khoa': 170,\n",
       " 'nghe': 171,\n",
       " '7': 172,\n",
       " 'á': 173,\n",
       " 'phải': 174,\n",
       " 'điểm': 175,\n",
       " 'hình': 176,\n",
       " 'những': 177,\n",
       " 'xe': 178,\n",
       " 'việt': 179,\n",
       " 'hơn': 180,\n",
       " 'quán': 181,\n",
       " 'bị': 182,\n",
       " 'tớ': 183,\n",
       " 'rất': 184,\n",
       " 'thao': 185,\n",
       " 'đã': 186,\n",
       " 'an': 187,\n",
       " 'định': 188,\n",
       " 'nhau': 189,\n",
       " 'phố': 190,\n",
       " 'nghĩ': 191,\n",
       " 'thứ': 192,\n",
       " 'ba': 193,\n",
       " 'nội': 194,\n",
       " 'hồ': 195,\n",
       " 'thắng': 196,\n",
       " 'tới': 197,\n",
       " 'hùng': 198,\n",
       " 'đức': 199,\n",
       " 'sài': 200,\n",
       " 'lên': 201,\n",
       " 'nên': 202,\n",
       " 'bố': 203,\n",
       " 'coi': 204,\n",
       " 'mai': 205,\n",
       " 'cùng': 206,\n",
       " 'tuần': 207,\n",
       " 'hành': 208,\n",
       " 'nặng': 209,\n",
       " 'trai': 210,\n",
       " 'tầm': 211,\n",
       " 'tôn': 212,\n",
       " 'bánh': 213,\n",
       " 'nè': 214,\n",
       " 'ừ': 215,\n",
       " 'nói': 216,\n",
       " 'đường': 217,\n",
       " 'lớp': 218,\n",
       " 'quần': 219,\n",
       " 'gòn': 220,\n",
       " 'lại': 221,\n",
       " 'rủ': 222,\n",
       " 'nhạc': 223,\n",
       " 'nhé': 224,\n",
       " 'đến': 225,\n",
       " 'vì': 226,\n",
       " 'chắc': 227,\n",
       " 'gì': 228,\n",
       " 'thêm': 229,\n",
       " 'hết': 230,\n",
       " 'tối': 231,\n",
       " 'cơm': 232,\n",
       " 'sở': 233,\n",
       " 'bằng': 234,\n",
       " 'chi': 235,\n",
       " 'cảm': 236,\n",
       " 'mét': 237,\n",
       " 'cách': 238,\n",
       " 'tiếng': 239,\n",
       " 'nghệ': 240,\n",
       " 'tui': 241,\n",
       " 'đủ': 242,\n",
       " 'đúng': 243,\n",
       " 'lễ': 244,\n",
       " 'long': 245,\n",
       " '10': 246,\n",
       " 'bóng': 247,\n",
       " 'xinh': 248,\n",
       " 'nhớ': 249,\n",
       " 'thuê': 250,\n",
       " 'rãnh': 251,\n",
       " 'số': 252,\n",
       " 'địa': 253,\n",
       " 'sau': 254,\n",
       " 'trọ': 255,\n",
       " 'nhưng': 256,\n",
       " 'giỏi': 257,\n",
       " 'phí': 258,\n",
       " 'hả': 259,\n",
       " 'họ': 260,\n",
       " 'uống': 261,\n",
       " 'các': 262,\n",
       " 'bán': 263,\n",
       " 'hà': 264,\n",
       " 'tân': 265,\n",
       " '6': 266,\n",
       " '21': 267,\n",
       " 'món': 268,\n",
       " 'trung': 269,\n",
       " 'nơi': 270,\n",
       " 'chủ': 271,\n",
       " 'hai': 272,\n",
       " 'tâm': 273,\n",
       " 'shop': 274,\n",
       " 'okay': 275,\n",
       " 'trên': 276,\n",
       " 'cầu': 277,\n",
       " 'khá': 278,\n",
       " 'hiện': 279,\n",
       " 'đấy': 280,\n",
       " 'cần': 281,\n",
       " '12': 282,\n",
       " 'quá': 283,\n",
       " 'trình': 284,\n",
       " 'có': 285,\n",
       " 'quốc': 286,\n",
       " 'ngủ': 287,\n",
       " 'trả': 288,\n",
       " 'laptop': 289,\n",
       " 'qua': 290,\n",
       " 'cà': 291,\n",
       " 'màu': 292,\n",
       " 'thư': 293,\n",
       " 'chí': 294,\n",
       " 'nhiên': 295,\n",
       " 'trước': 296,\n",
       " 'lần': 297,\n",
       " 'net': 298,\n",
       " 'thời': 299,\n",
       " 'khác': 300,\n",
       " 'ê': 301,\n",
       " 'kí': 302,\n",
       " 'quen': 303,\n",
       " 'cuối': 304,\n",
       " 'ninh': 305,\n",
       " 'thương': 306,\n",
       " 'dài': 307,\n",
       " 'ạ': 308,\n",
       " 'hoặc': 309,\n",
       " 'khó': 310,\n",
       " 'tay': 311,\n",
       " 'm': 312,\n",
       " 'trang': 313,\n",
       " 'cũ': 314,\n",
       " 'tất': 315,\n",
       " 'đứa': 316,\n",
       " 'tập': 317,\n",
       " 'mùng': 318,\n",
       " 'iphone': 319,\n",
       " 'viện': 320,\n",
       " 'nếu': 321,\n",
       " 'đông': 322,\n",
       " 'tự': 323,\n",
       " 'chọn': 324,\n",
       " 'ít': 325,\n",
       " 'xong': 326,\n",
       " 'gà': 327,\n",
       " 'sách': 328,\n",
       " 'nhân': 329,\n",
       " 'bên': 330,\n",
       " 'xin': 331,\n",
       " 'lập': 332,\n",
       " 'gặp': 333,\n",
       " 'buồn': 334,\n",
       " '8': 335,\n",
       " '30': 336,\n",
       " 'mỗi': 337,\n",
       " 'kinh': 338,\n",
       " 'nguyễn': 339,\n",
       " 'thị': 340,\n",
       " 'trà': 341,\n",
       " 'bò': 342,\n",
       " 'cô': 343,\n",
       " 'mẫu': 344,\n",
       " 'dịp': 345,\n",
       " 'làm': 346,\n",
       " 'ty': 347,\n",
       " 'vừa': 348,\n",
       " 'hong': 349,\n",
       " 'miền': 350,\n",
       " 'bộ': 351,\n",
       " 'phê': 352,\n",
       " 'hôm': 353,\n",
       " 'lan': 354,\n",
       " 'chất': 355,\n",
       " 'bảo': 356,\n",
       " 'trái': 357,\n",
       " 'văn': 358,\n",
       " 'mặc': 359,\n",
       " 'size': 360,\n",
       " 'thanh': 361,\n",
       " 'tdtu': 362,\n",
       " 'bơi': 363,\n",
       " 'chuyên': 364,\n",
       " 'tiện': 365,\n",
       " 'nữ': 366,\n",
       " 'sự': 367,\n",
       " 'bro': 368,\n",
       " 'bài': 369,\n",
       " 'dạo': 370,\n",
       " 'tàu': 371,\n",
       " 't': 372,\n",
       " 'chia': 373,\n",
       " 'tùy': 374,\n",
       " 'ở': 375,\n",
       " 'xá': 376,\n",
       " 'đặt': 377,\n",
       " 'bắc': 378,\n",
       " 'rộng': 379,\n",
       " 'ừm': 380,\n",
       " 'đất': 381,\n",
       " 'giang': 382,\n",
       " 'ghét': 383,\n",
       " 'banh': 384,\n",
       " 'giải': 385,\n",
       " 'rớt': 386,\n",
       " 'hồi': 387,\n",
       " 'toán': 388,\n",
       " 'túc': 389,\n",
       " 'chiều': 390,\n",
       " 'hông': 391,\n",
       " 'giàu': 392,\n",
       " 'khoảng': 393,\n",
       " 'nhật': 394,\n",
       " 'hoa': 395,\n",
       " 'samsung': 396,\n",
       " 'hơi': 397,\n",
       " 'bún': 398,\n",
       " 'cây': 399,\n",
       " 'thích': 400,\n",
       " 'từng': 401,\n",
       " 'đánh': 402,\n",
       " 'chào': 403,\n",
       " 'giới': 404,\n",
       " 'kì': 405,\n",
       " 'lý': 406,\n",
       " 'sắp': 407,\n",
       " 'tham': 408,\n",
       " 'xuyên': 409,\n",
       " '9': 410,\n",
       " 'cảnh': 411,\n",
       " 'thiết': 412,\n",
       " 'biển': 413,\n",
       " 'hè': 414,\n",
       " 'nhỏ': 415,\n",
       " 'thầy': 416,\n",
       " 'hãng': 417,\n",
       " 'gian': 418,\n",
       " 'rạp': 419,\n",
       " 'sẽ': 420,\n",
       " 'cơ': 421,\n",
       " 'cân': 422,\n",
       " 'ký': 423,\n",
       " 'chừng': 424,\n",
       " 'thịt': 425,\n",
       " 'cực': 426,\n",
       " 'cntt': 427,\n",
       " 'dịch': 428,\n",
       " 'trí': 429,\n",
       " 'ý': 430,\n",
       " 'cửa': 431,\n",
       " 'ta': 432,\n",
       " 'này': 433,\n",
       " 'tưởng': 434,\n",
       " 'đầu': 435,\n",
       " 'ấy': 436,\n",
       " 'đen': 437,\n",
       " 'hóa': 438,\n",
       " 'oke': 439,\n",
       " 'thoảng': 440,\n",
       " 'ơi': 441,\n",
       " 'dân': 442,\n",
       " 'xài': 443,\n",
       " 'theo': 444,\n",
       " 'tương': 445,\n",
       " 'bà': 446,\n",
       " 'thằng': 447,\n",
       " 'hệ': 448,\n",
       " 'thiện': 449,\n",
       " 'chợ': 450,\n",
       " 'hương': 451,\n",
       " 'đọc': 452,\n",
       " 'dẫn': 453,\n",
       " 'it': 454,\n",
       " 'sữa': 455,\n",
       " 'lẩu': 456,\n",
       " 'thỉnh': 457,\n",
       " '22': 458,\n",
       " 'vật': 459,\n",
       " 'đắt': 460,\n",
       " 'cấp': 461,\n",
       " 'nhỉ': 462,\n",
       " 'chạy': 463,\n",
       " 'giúp': 464,\n",
       " 'giảm': 465,\n",
       " 'khùng': 466,\n",
       " 'khỏe': 467,\n",
       " 'tây': 468,\n",
       " 'vé': 469,\n",
       " 'thống': 470,\n",
       " '11': 471,\n",
       " 'lê': 472,\n",
       " 'nẵng': 473,\n",
       " 'vũng': 474,\n",
       " 'toàn': 475,\n",
       " 'vài': 476,\n",
       " 'xanh': 477,\n",
       " 'đôi': 478,\n",
       " 'di': 479,\n",
       " 'nhậu': 480,\n",
       " 'phở': 481,\n",
       " 'châu': 482,\n",
       " 'quảng': 483,\n",
       " 'bắt': 484,\n",
       " 'ca': 485,\n",
       " 'thi': 486,\n",
       " 'vô': 487,\n",
       " 'giáo': 488,\n",
       " 'dạy': 489,\n",
       " 'vẫn': 490,\n",
       " 'biệt': 491,\n",
       " 'mái': 492,\n",
       " 'kiếm': 493,\n",
       " 'dự': 494,\n",
       " 'thực': 495,\n",
       " 'truyền': 496,\n",
       " 'dương': 497,\n",
       " 'liệu': 498,\n",
       " '15': 499,\n",
       " 'rẻ': 500,\n",
       " 'mỹ': 501,\n",
       " 'tim': 502,\n",
       " 'lời': 503,\n",
       " 'trị': 504,\n",
       " 'kiểu': 505,\n",
       " 'hoạt': 506,\n",
       " 'liên': 507,\n",
       " 'ngoại': 508,\n",
       " 'lai': 509,\n",
       " 'tín': 510,\n",
       " 'nhìn': 511,\n",
       " 'trạng': 512,\n",
       " 'dị': 513,\n",
       " 'chán': 514,\n",
       " 'sáng': 515,\n",
       " 'rồi': 516,\n",
       " 'vậy': 517,\n",
       " 'phần': 518,\n",
       " 'lao': 519,\n",
       " 'hội': 520,\n",
       " 'xuất': 521,\n",
       " 'huế': 522,\n",
       " 'khách': 523,\n",
       " 'mặt': 524,\n",
       " 'tặng': 525,\n",
       " 'phục': 526,\n",
       " 'phong': 527,\n",
       " 'giác': 528,\n",
       " '100': 529,\n",
       " 'trưa': 530,\n",
       " 'chả': 531,\n",
       " 'covid': 532,\n",
       " 'chính': 533,\n",
       " 'kỹ': 534,\n",
       " 'chuyện': 535,\n",
       " 'bay': 536,\n",
       " 'nào': 537,\n",
       " 'điều': 538,\n",
       " 'học': 539,\n",
       " 'chó': 540,\n",
       " 'dòng': 541,\n",
       " 'tỉnh': 542,\n",
       " 'độ': 543,\n",
       " 'chuẩn': 544,\n",
       " 'tụi': 545,\n",
       " 'tư': 546,\n",
       " 'tiết': 547,\n",
       " 'tế': 548,\n",
       " 'đêm': 549,\n",
       " 'trời': 550,\n",
       " 'bận': 551,\n",
       " 'thử': 552,\n",
       " 'dục': 553,\n",
       " 'khu': 554,\n",
       " 'web': 555,\n",
       " 'tạo': 556,\n",
       " 'ko': 557,\n",
       " 'thuật': 558,\n",
       " 'ế': 559,\n",
       " 'siêu': 560,\n",
       " 'robot': 561,\n",
       " 'nhiệt': 562,\n",
       " 'đậu': 563,\n",
       " 'tp': 564,\n",
       " 'thủ': 565,\n",
       " 'âm': 566,\n",
       " 'ngu': 567,\n",
       " 'kỳ': 568,\n",
       " 'đổi': 569,\n",
       " 'hài': 570,\n",
       " 'dùng': 571,\n",
       " 'bạn': 572,\n",
       " 'cá': 573,\n",
       " 'câu': 574,\n",
       " 'vợ': 575,\n",
       " 'nhà': 576,\n",
       " 'mày': 577,\n",
       " 'thoải': 578,\n",
       " 'sếp': 579,\n",
       " 'mọi': 580,\n",
       " 'hợp': 581,\n",
       " 'thuận': 582,\n",
       " 'lì': 583,\n",
       " 'xì': 584,\n",
       " 'lớn': 585,\n",
       " 'quang': 586,\n",
       " 'giao': 587,\n",
       " 'mất': 588,\n",
       " 'nhá': 589,\n",
       " 'núi': 590,\n",
       " 'sắm': 591,\n",
       " 'phú': 592,\n",
       " 'lạnh': 593,\n",
       " 'bản': 594,\n",
       " '1m7': 595,\n",
       " 'ship': 596,\n",
       " 'lượng': 597,\n",
       " 'cafe': 598,\n",
       " 'nổi': 599,\n",
       " 'tam': 600,\n",
       " 'lotte': 601,\n",
       " 'hcm': 602,\n",
       " 'trắng': 603,\n",
       " 'buôn': 604,\n",
       " 'tài': 605,\n",
       " 'củ': 606,\n",
       " 'kia': 607,\n",
       " 'sân': 608,\n",
       " 'ha': 609,\n",
       " 'sĩ': 610,\n",
       " 'riêng': 611,\n",
       " 'sợ': 612,\n",
       " 'dụng': 613,\n",
       " 'tượng': 614,\n",
       " 'facebook': 615,\n",
       " 'đầy': 616,\n",
       " 'vụ': 617,\n",
       " 'ngữ': 618,\n",
       " 'đợt': 619,\n",
       " 'hòa': 620,\n",
       " 'lợi': 621,\n",
       " 'haha': 622,\n",
       " 'được': 623,\n",
       " 'vẻ': 624,\n",
       " 'tí': 625,\n",
       " 'xuân': 626,\n",
       " 'kế': 627,\n",
       " 'giày': 628,\n",
       " 'nhận': 629,\n",
       " '2021': 630,\n",
       " 'vuông': 631,\n",
       " '13': 632,\n",
       " 'sapa': 633,\n",
       " 'dưới': 634,\n",
       " 'asus': 635,\n",
       " 'nấu': 636,\n",
       " 'cua': 637,\n",
       " 'cộng': 638,\n",
       " 'đối': 639,\n",
       " 'đương': 640,\n",
       " 'chân': 641,\n",
       " 'to': 642,\n",
       " 'hủ': 643,\n",
       " 'thèm': 644,\n",
       " 'tấm': 645,\n",
       " 'má': 646,\n",
       " 'mì': 647,\n",
       " 'hiền': 648,\n",
       " 'thật': 649,\n",
       " 'đừng': 650,\n",
       " '50': 651,\n",
       " 'mát': 652,\n",
       " 'doanh': 653,\n",
       " 'lông': 654,\n",
       " 'hát': 655,\n",
       " 'đấu': 656,\n",
       " 'rổ': 657,\n",
       " 'cờ': 658,\n",
       " 'lực': 659,\n",
       " 'mắc': 660,\n",
       " 'hạ': 661,\n",
       " 'sơ': 662,\n",
       " 'mèo': 663,\n",
       " 'ssd': 664,\n",
       " 'do': 665,\n",
       " 'mệt': 666,\n",
       " 'tỷ': 667,\n",
       " 'cụ': 668,\n",
       " 'tìm': 669,\n",
       " 'thất': 670,\n",
       " 'sơn': 671,\n",
       " 'dọn': 672,\n",
       " '14': 673,\n",
       " 'chút': 674,\n",
       " 'đơn': 675,\n",
       " 'galaxy': 676,\n",
       " 'giờ': 677,\n",
       " 'cgv': 678,\n",
       " 'ừa': 679,\n",
       " '19': 680,\n",
       " 'áo': 681,\n",
       " 'đợi': 682,\n",
       " 'mạng': 683,\n",
       " 'tòa': 684,\n",
       " 'gu': 685,\n",
       " 'tỏ': 686,\n",
       " 'ờ': 687,\n",
       " 'thang': 688,\n",
       " 'vịt': 689,\n",
       " 'tiếu': 690,\n",
       " 'tráng': 691,\n",
       " 'phút': 692,\n",
       " 'nằm': 693,\n",
       " 'phan': 694,\n",
       " 'tròn': 695,\n",
       " 'hề': 696,\n",
       " 'tạm': 697,\n",
       " 'nghìn': 698,\n",
       " 'rỗi': 699,\n",
       " 'quả': 700,\n",
       " 'phường': 701,\n",
       " 'lận': 702,\n",
       " 'tích': 703,\n",
       " 'áp': 704,\n",
       " 'mơ': 705,\n",
       " 'độc': 706,\n",
       " 'năng': 707,\n",
       " 'đó': 708,\n",
       " 'dữ': 709,\n",
       " 'đa': 710,\n",
       " 'mà': 711,\n",
       " 'thu': 712,\n",
       " 'chùa': 713,\n",
       " 'khánh': 714,\n",
       " 'dẹp': 715,\n",
       " 'online': 716,\n",
       " 'bây': 717,\n",
       " 'mau': 718,\n",
       " 'mãi': 719,\n",
       " 'thái': 720,\n",
       " 'mắt': 721,\n",
       " 'ly': 722,\n",
       " 'tiếp': 723,\n",
       " 'trọng': 724,\n",
       " 'ích': 725,\n",
       " 'kể': 726,\n",
       " 'ngôn': 727,\n",
       " 'càng': 728,\n",
       " 'trở': 729,\n",
       " 'bến': 730,\n",
       " 'phát': 731,\n",
       " 'cắm': 732,\n",
       " 'vũ': 733,\n",
       " '16': 734,\n",
       " 'ma': 735,\n",
       " '18': 736,\n",
       " 'mềm': 737,\n",
       " 'tdt': 738,\n",
       " 'rõ': 739,\n",
       " '1999': 740,\n",
       " 'duy': 741,\n",
       " 'tiến': 742,\n",
       " 'chục': 743,\n",
       " 'mạnh': 744,\n",
       " 'kệ': 745,\n",
       " 'lo': 746,\n",
       " 'lành': 747,\n",
       " 'diễn': 748,\n",
       " 'hữu': 749,\n",
       " 'đh': 750,\n",
       " 'ấn': 751,\n",
       " 'lạc': 752,\n",
       " 'ước': 753,\n",
       " 'nhóm': 754,\n",
       " 'dư': 755,\n",
       " 'quân': 756,\n",
       " 'nghèo': 757,\n",
       " 'chú': 758,\n",
       " 'vấn': 759,\n",
       " 'quên': 760,\n",
       " 'thế': 761,\n",
       " 'vị': 762,\n",
       " 'môi': 763,\n",
       " 'nhập': 764,\n",
       " 'còn': 765,\n",
       " 'chức': 766,\n",
       " 'giảng': 767,\n",
       " 'tổ': 768,\n",
       " 'thăm': 769,\n",
       " 'phụ': 770,\n",
       " 'nhắn': 771,\n",
       " 'gồm': 772,\n",
       " 'đóng': 773,\n",
       " 'chốt': 774,\n",
       " 'mở': 775,\n",
       " 'vải': 776,\n",
       " 'giữ': 777,\n",
       " 'lấy': 778,\n",
       " 'đầm': 779,\n",
       " 'nhanh': 780,\n",
       " 'dell': 781,\n",
       " 'tận': 782,\n",
       " 'tiệm': 783,\n",
       " 'kho': 784,\n",
       " 'trợ': 785,\n",
       " 'góp': 786,\n",
       " 'thấp': 787,\n",
       " 'xl': 788,\n",
       " 'chuột': 789,\n",
       " 'shopping': 790,\n",
       " 'tử': 791,\n",
       " 'mập': 792,\n",
       " 'đời': 793,\n",
       " 'tệ': 794,\n",
       " 'đô': 795,\n",
       " 'kẹt': 796,\n",
       " 'đào': 797,\n",
       " 'ktx': 798,\n",
       " 'vãi': 799,\n",
       " 'giống': 800,\n",
       " 'đói': 801,\n",
       " 'hải': 802,\n",
       " 'trộn': 803,\n",
       " 'yên': 804,\n",
       " 'sắc': 805,\n",
       " 'ngọt': 806,\n",
       " 'diện': 807,\n",
       " 'bàn': 808,\n",
       " 'chim': 809,\n",
       " 'sừng': 810,\n",
       " 'lái': 811,\n",
       " 'hãy': 812,\n",
       " 'tuyệt': 813,\n",
       " 'điên': 814,\n",
       " 'cường': 815,\n",
       " 'lắm': 816,\n",
       " 'tphcm': 817,\n",
       " '2001': 818,\n",
       " 'fpt': 819,\n",
       " 'dạ': 820,\n",
       " 'chắn': 821,\n",
       " '500': 822,\n",
       " 'rưỡi': 823,\n",
       " 'zay': 824,\n",
       " 'vực': 825,\n",
       " 'chương': 826,\n",
       " 'bổng': 827,\n",
       " 'chỗ': 828,\n",
       " 'đạt': 829,\n",
       " 'đỡ': 830,\n",
       " 'người': 831,\n",
       " 'quyết': 832,\n",
       " 'hot': 833,\n",
       " 'à': 834,\n",
       " 'đón': 835,\n",
       " 'chúc': 836,\n",
       " 'kèo': 837,\n",
       " 'ngay': 838,\n",
       " 'bữa': 839,\n",
       " 'viễn': 840,\n",
       " 'dắt': 841,\n",
       " 'mồng': 842,\n",
       " 'nghiệm': 843,\n",
       " 'ram': 844,\n",
       " 'pro': 845,\n",
       " 'cấu': 846,\n",
       " 'khoác': 847,\n",
       " 'chiếc': 848,\n",
       " 'khuyến': 849,\n",
       " 'bền': 850,\n",
       " 'macbook': 851,\n",
       " 'đăng': 852,\n",
       " 'ngắn': 853,\n",
       " 'mi': 854,\n",
       " 'jean': 855,\n",
       " 'nè': 856,\n",
       " 'tổng': 857,\n",
       " 'sang': 858,\n",
       " 'dỗi': 859,\n",
       " 'quỳnh': 860,\n",
       " 'cuộc': 861,\n",
       " 'ngại': 862,\n",
       " 'ốm': 863,\n",
       " 'buýt': 864,\n",
       " 'quy': 865,\n",
       " 'cố': 866,\n",
       " 'chứ': 867,\n",
       " 'song': 868,\n",
       " 'hiểu': 869,\n",
       " 'bí': 870,\n",
       " 'mưa': 871,\n",
       " 'trứng': 872,\n",
       " 'chổ': 873,\n",
       " 'rán': 874,\n",
       " 'cư': 875,\n",
       " 'km': 876,\n",
       " 'tịch': 877,\n",
       " 'vietnam': 878,\n",
       " 'lòng': 879,\n",
       " 'tre': 880,\n",
       " 'nai': 881,\n",
       " 'đám': 882,\n",
       " 'đẹp': 883,\n",
       " 'góc': 884,\n",
       " 'hạnh': 885,\n",
       " 'phúc': 886,\n",
       " 'út': 887,\n",
       " 'thọ': 888,\n",
       " '0': 889,\n",
       " 'tuấn': 890,\n",
       " 'tùng': 891,\n",
       " '2000': 892,\n",
       " 'kim': 893,\n",
       " 'hậu': 894,\n",
       " 'cũng': 895,\n",
       " 'đổ': 896,\n",
       " 'dừa': 897,\n",
       " 'cứ': 898,\n",
       " 'dạ': 899,\n",
       " 'chụp': 900,\n",
       " 'lĩnh': 901,\n",
       " 'khiến': 902,\n",
       " 'sắp': 903,\n",
       " 'trường': 904,\n",
       " 'yếu': 905,\n",
       " 'tầng': 906,\n",
       " 'đội': 907,\n",
       " 'máu': 908,\n",
       " 'thuộc': 909,\n",
       " 'cung': 910,\n",
       " 'chết': 911,\n",
       " 'nghĩa': 912,\n",
       " 'bệnh': 913,\n",
       " 'phẩm': 914,\n",
       " 'core': 915,\n",
       " 'i': 916,\n",
       " 'cha': 917,\n",
       " 'danh': 918,\n",
       " 'chồng': 919,\n",
       " '25': 920,\n",
       " 'tính': 921,\n",
       " 'đem': 922,\n",
       " 'hoà': 923,\n",
       " 'thức': 924,\n",
       " 'bảy': 925,\n",
       " 'xử': 926,\n",
       " 'mê': 927,\n",
       " 'code': 928,\n",
       " 'mầy': 929,\n",
       " 'mấy': 930,\n",
       " 'ngày': 931,\n",
       " 'mười': 932,\n",
       " 'triển': 933,\n",
       " 'thẻ': 934,\n",
       " 'rap': 935,\n",
       " 'lol': 936,\n",
       " 'đoán': 937,\n",
       " 'cặp': 938,\n",
       " 'thú': 939,\n",
       " 'leo': 940,\n",
       " 'phượt': 941,\n",
       " 'sạn': 942,\n",
       " 'hoài': 943,\n",
       " 'quà': 944,\n",
       " 'trải': 945,\n",
       " 'mã': 946,\n",
       " 'uy': 947,\n",
       " 'hiệu': 948,\n",
       " 'chuyển': 949,\n",
       " 'cổng': 950,\n",
       " 'lười': 951,\n",
       " 'hút': 952,\n",
       " 'rèn': 953,\n",
       " 'xét': 954,\n",
       " 'adidas': 955,\n",
       " 'cỡ': 956,\n",
       " 's20': 957,\n",
       " 'tiên': 958,\n",
       " 'ứng': 959,\n",
       " 'chối': 960,\n",
       " 'tán': 961,\n",
       " 'ưa': 962,\n",
       " 'chờ': 963,\n",
       " 'đều': 964,\n",
       " 'ny': 965,\n",
       " 'gầy': 966,\n",
       " 'thuốc': 967,\n",
       " 'mối': 968,\n",
       " 'tđt': 969,\n",
       " 'ảo': 970,\n",
       " 'rau': 971,\n",
       " 'khỏi': 972,\n",
       " 'ấy': 973,\n",
       " 'duyên': 974,\n",
       " 'cạnh': 975,\n",
       " 'nguyên': 976,\n",
       " 'bác': 977,\n",
       " 'thiên': 978,\n",
       " 'you': 979,\n",
       " 'mắm': 980,\n",
       " 'gọi': 981,\n",
       " 'no': 982,\n",
       " 'lun': 983,\n",
       " 'bia': 984,\n",
       " 'rượu': 985,\n",
       " 'kfc': 986,\n",
       " 'nướng': 987,\n",
       " 'canteen': 988,\n",
       " 'bếp': 989,\n",
       " 'ghép': 990,\n",
       " 'nghi': 991,\n",
       " 'hẻm': 992,\n",
       " 'đoạn': 993,\n",
       " 'chứa': 994,\n",
       " 'tắm': 995,\n",
       " 'vĩnh': 996,\n",
       " 'ngựa': 997,\n",
       " 'vỉa': 998,\n",
       " 'elip': 999,\n",
       " 'dành': 1000,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f10f918",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#trích thành các từ xl các kí tự đặc biệt\n",
    "vocab = []\n",
    "for word in tokenizer.word_index:\n",
    "  vocab.append(word)\n",
    "\n",
    "def tokenize(sentences):\n",
    "  tokens_list = []\n",
    "  vocabulary = []\n",
    "  for sentence in sentences:\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    tokens = sentence.split()\n",
    "    vocabulary += tokens\n",
    "    tokens_list.append(tokens)\n",
    "  return tokens_list, vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27b84f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoder_input_data (5899, 93) 93\n",
      "Thích mẫu người nào\n",
      "[ 13 344  16  11   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "#encoder_input_data mã hóa câu hỏi thành vector số(one hot vector)\n",
    "tokenized_questions = tokenizer.texts_to_sequences( questions )\n",
    "maxlen_questions = max( [len(x) for x in tokenized_questions ] )\n",
    "padded_questions = preprocessing.sequence.pad_sequences( tokenized_questions, maxlen = maxlen_questions, padding = 'post')\n",
    "encoder_input_data = np.array(padded_questions)\n",
    "print()\n",
    "print(\"Encoder_input_data\",encoder_input_data.shape, maxlen_questions)\n",
    "print(questions[0])\n",
    "print(encoder_input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d657e6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder_input_data (5899, 62) 62\n",
      "<START> Dễ thương, tóc dài, da trắng <END>\n",
      "[   2  160  306 1645  307 2261  603    1    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# decoder_input_data mã hóa câu trả lời thành vector số\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "maxlen_answers = max( [ len(x) for x in tokenized_answers ] )\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "decoder_input_data = np.array( padded_answers )\n",
    "print(  )\n",
    "print(\"Decoder_input_data\",decoder_input_data.shape , maxlen_answers)\n",
    "print(answers[0])\n",
    "print(decoder_input_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a14e6793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decoder_output_data (5899, 62, 3097)\n",
      "<START> Dễ thương, tóc dài, da trắng <END>\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# decoder_output_data giải mã từ vector số sang string\n",
    "tokenized_answers = tokenizer.texts_to_sequences( answers )\n",
    "for i in range(len(tokenized_answers)) :\n",
    "    tokenized_answers[i] = tokenized_answers[i][1:]\n",
    "padded_answers = preprocessing.sequence.pad_sequences( tokenized_answers , maxlen=maxlen_answers , padding='post' )\n",
    "onehot_answers = utils.to_categorical( padded_answers , VOCAB_SIZE )\n",
    "decoder_output_data = np.array( onehot_answers )\n",
    "print(  )\n",
    "print(\"Decoder_output_data\", decoder_output_data.shape)\n",
    "print(answers[0])\n",
    "print(decoder_output_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5baa9827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\PC\\AppData\\Local\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 93)]                 0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, 62)]                 0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 93, 200)              619400    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 62, 200)              619400    ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(None, 200),                320800    ['embedding[0][0]']           \n",
      "                              (None, 200),                                                        \n",
      "                              (None, 200)]                                                        \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(None, 62, 200),            320800    ['embedding_1[0][0]',         \n",
      "                              (None, 200),                           'lstm[0][1]',                \n",
      "                              (None, 200)]                           'lstm[0][2]']                \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 62, 3097)             622497    ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2502897 (9.55 MB)\n",
      "Trainable params: 2502897 (9.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#khởi tạo mô hình lstm\n",
    "encoder_inputs = tf.keras.layers.Input(shape=( maxlen_questions , ))\n",
    "encoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True ) (encoder_inputs)\n",
    "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 200 , return_state=True )( encoder_embedding )\n",
    "encoder_states = [ state_h , state_c ]\n",
    "\n",
    "decoder_inputs = tf.keras.layers.Input(shape=( maxlen_answers ,  ))\n",
    "decoder_embedding = tf.keras.layers.Embedding( VOCAB_SIZE, 200 , mask_zero=True) (decoder_inputs)\n",
    "decoder_lstm = tf.keras.layers.LSTM( 200 , return_state=True , return_sequences=True )\n",
    "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
    "decoder_dense = tf.keras.layers.Dense( VOCAB_SIZE , activation=tf.keras.activations.softmax ) \n",
    "output = decoder_dense ( decoder_outputs )\n",
    "\n",
    "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size= 10, epochs=1 ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5887483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "590/590 [==============================] - 133s 225ms/step - loss: 4.2115\n",
      "Epoch 2/2\n",
      "590/590 [==============================] - 140s 237ms/step - loss: 4.1108\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c657ba0b90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([encoder_input_data , decoder_input_data], decoder_output_data, batch_size= 10, epochs=2 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0280f5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fff569f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3ba0332e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ham thu mo hinh ,nhận đàu vào là 1 câu hỏi, đầu ra: câu trả lời\n",
    "def make_inference_models():\n",
    "    \n",
    "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
    "    \n",
    "    decoder_state_input_h = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    decoder_state_input_c = tf.keras.layers.Input(shape=( 200 ,))\n",
    "    \n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    \n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "        decoder_embedding , initial_state=decoder_states_inputs)\n",
    "    \n",
    "    decoder_states = [state_h, state_c]\n",
    "\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    \n",
    "    decoder_model = tf.keras.models.Model(\n",
    "        [decoder_inputs] + decoder_states_inputs,\n",
    "        [decoder_outputs] + decoder_states)\n",
    "    \n",
    "    return encoder_model , decoder_model\n",
    "    \n",
    "def str_to_tokens( sentence : str ):\n",
    "\n",
    "    words = sentence.lower().split()\n",
    "    tokens_list = list()\n",
    "  \n",
    "    for word in words:\n",
    "        tokens_list.append( tokenizer.word_index[ word ] ) \n",
    "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=maxlen_questions , padding='post')\n",
    "\n",
    "enc_model , dec_model = make_inference_models()\n",
    "\n",
    "def chat_bot_lstm(cau_hoi):\n",
    "    states_values = enc_model.predict( str_to_tokens( cau_hoi ) )\n",
    "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
    "    empty_target_seq[0, 0] = tokenizer.word_index['start']\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "    while not stop_condition :\n",
    "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
    "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
    "        sampled_word = None\n",
    "        for word , index in tokenizer.word_index.items() :\n",
    "            if sampled_word_index == index :\n",
    "                decoded_translation += ' {}'.format( word )\n",
    "                sampled_word = word\n",
    "        if sampled_word == 'end' or len(decoded_translation.split()) > maxlen_answers:\n",
    "            stop_condition = True\n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        states_values = [ h , c ] \n",
    "        print(decoded_translation)\n",
    "    return ( decoded_translation[1:-4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "713d6459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      " sài\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      " sài gòn\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      " sài gòn end\n",
      "sài gòn\n"
     ]
    }
   ],
   "source": [
    "print(chat_bot_lstm(\"quê bạn ở đâu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dce1d8f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      " người\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      " người yêu\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      " người yêu quận\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      " người yêu quận 7\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      " người yêu quận 7 end\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      " có\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      " có end\n",
      "1/1 [==============================] - 0s 62ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Local\\anaconda3\\Lib\\site-packages\\nltk\\translate\\bleu_score.py:552: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 42ms/step\n",
      " vì\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      " vì vì\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      " vì vì tao\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      " vì vì tao thích\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      " vì vì tao thích bạn\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      " vì vì tao thích bạn end\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      " có\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      " có end\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      " không\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      " không end\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      " có\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      " có nhiều\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      " có nhiều end\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      " cũng\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      " cũng hay\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      " cũng hay đi\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      " cũng hay đi end\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      " có\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      " có nhiều\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      " có nhiều lắm\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      " có nhiều lắm rất\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      " có nhiều lắm rất xinh\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      " có nhiều lắm rất xinh end\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      " thích\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      " thích đá\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      " thích đá bóng\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      " thích đá bóng end\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      " có\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      " có end\n",
      "Điểm số đánh giá BLEU score đạt được 0.9052126138055366\n"
     ]
    }
   ],
   "source": [
    "questions\n",
    "answers\n",
    "BLEU_score = 0\n",
    "for i in range(100):\n",
    "    try:\n",
    "        BLEU_score += nltk.translate.bleu_score.sentence_bleu([answers[i]],chat_bot_lstm(questions[i]), weights = (0.5, 0.5))\n",
    "    except: \n",
    "        BLEU_score += 1\n",
    "print(\"Điểm số đánh giá BLEU score đạt được\",BLEU_score/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "4bcf5b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a35ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
